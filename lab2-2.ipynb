{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFQQia7tRB_N"
      },
      "source": [
        "# Створення нових українських слів\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реалізуємо RNN на рівні символів"
      ],
      "metadata": {
        "id": "lkga81Zt2K9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSJlneq_GrK",
        "outputId": "f3223fe6-584f-4ee1-f680-02700bea375f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 1.7122\n",
            "Epoch [2/100], Loss: 0.7629\n",
            "Epoch [3/100], Loss: 0.5855\n",
            "Epoch [4/100], Loss: 0.4729\n",
            "Epoch [5/100], Loss: 0.3890\n",
            "Epoch [6/100], Loss: 0.3214\n",
            "Epoch [7/100], Loss: 0.2612\n",
            "Epoch [8/100], Loss: 0.2097\n",
            "Epoch [9/100], Loss: 0.1687\n",
            "Epoch [10/100], Loss: 0.1314\n",
            "Epoch [11/100], Loss: 0.1041\n",
            "Epoch [12/100], Loss: 0.0835\n",
            "Epoch [13/100], Loss: 0.0699\n",
            "Epoch [14/100], Loss: 0.0573\n",
            "Epoch [15/100], Loss: 0.0502\n",
            "Epoch [16/100], Loss: 0.0445\n",
            "Epoch [17/100], Loss: 0.0410\n",
            "Epoch [18/100], Loss: 0.0373\n",
            "Epoch [19/100], Loss: 0.0334\n",
            "Epoch [20/100], Loss: 0.0326\n",
            "Epoch [21/100], Loss: 0.0309\n",
            "Epoch [22/100], Loss: 0.0289\n",
            "Epoch [23/100], Loss: 0.0290\n",
            "Epoch [24/100], Loss: 0.0268\n",
            "Epoch [25/100], Loss: 0.0265\n",
            "Epoch [26/100], Loss: 0.0257\n",
            "Epoch [27/100], Loss: 0.0247\n",
            "Epoch [28/100], Loss: 0.0239\n",
            "Epoch [29/100], Loss: 0.0232\n",
            "Epoch [30/100], Loss: 0.0239\n",
            "Epoch [31/100], Loss: 0.0231\n",
            "Epoch [32/100], Loss: 0.0223\n",
            "Epoch [33/100], Loss: 0.0219\n",
            "Epoch [34/100], Loss: 0.0221\n",
            "Epoch [35/100], Loss: 0.0222\n",
            "Epoch [36/100], Loss: 0.0215\n",
            "Epoch [37/100], Loss: 0.0200\n",
            "Epoch [38/100], Loss: 0.0209\n",
            "Epoch [39/100], Loss: 0.0209\n",
            "Epoch [40/100], Loss: 0.0201\n",
            "Epoch [41/100], Loss: 0.0206\n",
            "Epoch [42/100], Loss: 0.0200\n",
            "Epoch [43/100], Loss: 0.0203\n",
            "Epoch [44/100], Loss: 0.0206\n",
            "Epoch [45/100], Loss: 0.0200\n",
            "Epoch [46/100], Loss: 0.0191\n",
            "Epoch [47/100], Loss: 0.0188\n",
            "Epoch [48/100], Loss: 0.0202\n",
            "Epoch [49/100], Loss: 0.0200\n",
            "Epoch [50/100], Loss: 0.0196\n",
            "Epoch [51/100], Loss: 0.0193\n",
            "Epoch [52/100], Loss: 0.0191\n",
            "Epoch [53/100], Loss: 0.0185\n",
            "Epoch [54/100], Loss: 0.0191\n",
            "Epoch [55/100], Loss: 0.0188\n",
            "Epoch [56/100], Loss: 0.0185\n",
            "Epoch [57/100], Loss: 0.0187\n",
            "Epoch [58/100], Loss: 0.0185\n",
            "Epoch [59/100], Loss: 0.0183\n",
            "Epoch [60/100], Loss: 0.0187\n",
            "Epoch [61/100], Loss: 0.0192\n",
            "Epoch [62/100], Loss: 0.0187\n",
            "Epoch [63/100], Loss: 0.0185\n",
            "Epoch [64/100], Loss: 0.0191\n",
            "Epoch [65/100], Loss: 0.0186\n",
            "Epoch [66/100], Loss: 0.0190\n",
            "Epoch [67/100], Loss: 0.0185\n",
            "Epoch [68/100], Loss: 0.0184\n",
            "Epoch [69/100], Loss: 0.0179\n",
            "Epoch [70/100], Loss: 0.0186\n",
            "Epoch [71/100], Loss: 0.0187\n",
            "Epoch [72/100], Loss: 0.0183\n",
            "Epoch [73/100], Loss: 0.0184\n",
            "Epoch [74/100], Loss: 0.0183\n",
            "Epoch [75/100], Loss: 0.0178\n",
            "Epoch [76/100], Loss: 0.0184\n",
            "Epoch [77/100], Loss: 0.0192\n",
            "Epoch [78/100], Loss: 0.0177\n",
            "Epoch [79/100], Loss: 0.0181\n",
            "Epoch [80/100], Loss: 0.0178\n",
            "Epoch [81/100], Loss: 0.0182\n",
            "Epoch [82/100], Loss: 0.0176\n",
            "Epoch [83/100], Loss: 0.0179\n",
            "Epoch [84/100], Loss: 0.0185\n",
            "Epoch [85/100], Loss: 0.0178\n",
            "Epoch [86/100], Loss: 0.0170\n",
            "Epoch [87/100], Loss: 0.0178\n",
            "Epoch [88/100], Loss: 0.0175\n",
            "Epoch [89/100], Loss: 0.0169\n",
            "Epoch [90/100], Loss: 0.0170\n",
            "Epoch [91/100], Loss: 0.0178\n",
            "Epoch [92/100], Loss: 0.0178\n",
            "Epoch [93/100], Loss: 0.0180\n",
            "Epoch [94/100], Loss: 0.0170\n",
            "Epoch [95/100], Loss: 0.0170\n",
            "Epoch [96/100], Loss: 0.0175\n",
            "Epoch [97/100], Loss: 0.0178\n",
            "Epoch [98/100], Loss: 0.0181\n",
            "Epoch [99/100], Loss: 0.0180\n",
            "Epoch [100/100], Loss: 0.0182\n",
            "Generated word: гемнийнийнийний\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "\n",
        "ukrainian_words = [\n",
        "    \"день\", \"ніч\", \"сонце\", \"мило\", \"країна\", \"любов\", \"дружба\",\n",
        "    \"справа\", \"визивати\", \"робота\", \"комп'ютер\", \"вікно\", \"книга\",\n",
        "    \"автомобіль\", \"філм\", \"музика\", \"природа\", \"заклад\", \"ідея\",\n",
        "    \"програмування\", \"інновація\", \"екосистема\", \"інтелект\", \"комунікація\",\n",
        "    \"інформація\", \"економіка\", \"політика\", \"культурний\", \"історичний\",\n",
        "    \"науковий\", \"технологія\", \"інженер\", \"архітектор\", \"дизайнер\",\n",
        "    \"програміст\", \"веб-розробник\", \"дата\", \"аналітик\", \"менеджер\",\n",
        "    \"маркетинг\", \"реклама\", \"продаж\", \"кінцевий\", \"результат\", \"досягнення\",\n",
        "    \"стратегія\", \"планування\", \"організація\", \"координація\", \"командування\",\n",
        "    \"комунікація\", \"зворотній\", \"підсумок\", \"дискусія\", \"колаборативний\",\n",
        "    \"інноваційний\", \"діяльність\", \"функціонал\", \"інтеграція\", \"адаптація\",\n",
        "    \"скалкування\", \"перспективний\", \"потенціал\", \"реалізація\", \"імплементація\",\n",
        "    \"оптимізація\", \"автоматизація\", \"децентрализований\", \"блокчейн\", \"криптовалюта\",\n",
        "    \"інтернет\", \"перевага\", \"комплексний\", \"мультіфункціональний\", \"інноваційний\",\n",
        "    \"когнітивний\", \"інтелектуальний\", \"компетентний\", \"професійний\", \"експеримент\",\n",
        "    \"інновації\", \"дослідження\", \"аналіз\", \"синергетичний\", \"інтеграційний\",\n",
        "    \"комунікаційний\", \"інформаційний\", \"комп'ютерний\", \"програмний\", \"системний\",\n",
        "    \"база\", \"даних\", \"навчання\", \"машинний\", \"підприємство\", \"бізнес\",\n",
        "    \"інвестиції\", \"фінансовий\", \"корпоративний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\",\n",
        "    \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\",\n",
        "    \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\", \"маркетинговий\",\n",
        "    \"рекламний\", \"продажний\", \"маркетинговий\", \"рекламний\", \"продажний\"\n",
        "]\n",
        "chars = sorted(set(''.join(ukrainian_words)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "seq_length = 5\n",
        "inputs = []\n",
        "targets = []\n",
        "for word in ukrainian_words:\n",
        "    word = word.strip()\n",
        "    for i in range(len(word) - seq_length):\n",
        "        inputs.append([char_to_idx[c] for c in word[i:i+seq_length]])\n",
        "        targets.append(char_to_idx[word[i+seq_length]])\n",
        "\n",
        "input_tensor = torch.tensor(inputs, dtype=torch.long)\n",
        "target_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "class WordDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "dataset = WordDataset(input_tensor, target_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))\n",
        "\n",
        "embedding_size = 100\n",
        "hidden_size = 128\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = CharRNN(vocab_size, embedding_size, hidden_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs_batch, targets_batch in dataloader:\n",
        "        hidden = model.init_hidden(inputs_batch.size(0))\n",
        "\n",
        "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "        output, hidden = model(inputs_batch, hidden)\n",
        "        loss = criterion(output, targets_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "def generate_word(model, seed, max_length=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        seed_input = [char_to_idx[c] for c in seed]\n",
        "        input_seq = torch.tensor(seed_input, dtype=torch.long).unsqueeze(0)\n",
        "        hidden = model.init_hidden(1)\n",
        "        generated = seed_input.copy()\n",
        "\n",
        "        for _ in range(max_length - len(seed)):\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "            prob = nn.functional.softmax(output[0], dim=0)\n",
        "            top_prob, top_idx = torch.topk(prob, k=3)\n",
        "            selected_idx = random.choices(top_idx.tolist(), weights=top_prob.tolist(), k=1)[0]\n",
        "            generated.append(selected_idx)\n",
        "            input_seq = torch.tensor([selected_idx], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        generated_word = ''.join([idx_to_char[idx] for idx in generated])\n",
        "        return generated_word\n",
        "\n",
        "seed = \"ге\"\n",
        "new_word = generate_word(model, seed, max_length=15)\n",
        "print(f\"Generated word: {new_word}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UD Ukrainian corpus"
      ],
      "metadata": {
        "id": "-sS29UXXz1fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Ukrainian-IU/master/uk_iu-ud-train.conllu -O uk_iu-ud-train.conllu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRX3hSHfzzPM",
        "outputId": "e3d42782-abfd-45d5-c9fd-c4ecdc18ecf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-28 08:13:41--  https://raw.githubusercontent.com/UniversalDependencies/UD_Ukrainian-IU/master/uk_iu-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13165569 (13M) [text/plain]\n",
            "Saving to: ‘uk_iu-ud-train.conllu’\n",
            "\n",
            "uk_iu-ud-train.conl 100%[===================>]  12.56M  32.0MB/s    in 0.4s    \n",
            "\n",
            "2024-11-28 08:13:42 (32.0 MB/s) - ‘uk_iu-ud-train.conllu’ saved [13165569/13165569]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завантажуємо та виділяємо слова та їх морфологічні ознаки"
      ],
      "metadata": {
        "id": "3eADTumPz7Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "word_features = []\n",
        "\n",
        "with open('uk_iu-ud-train.conllu', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        if line.startswith('#') or line.strip() == '':\n",
        "            continue\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) != 10:\n",
        "            continue\n",
        "        if '-' in parts[0] or '.' in parts[0]:\n",
        "            continue\n",
        "        word = parts[1]\n",
        "        feats = parts[5]\n",
        "        pos = parts[3]\n",
        "\n",
        "        if word.isalpha():\n",
        "            word = word.lower()\n",
        "            gender = None\n",
        "            match = re.search(r'Gender=([A-Za-z]+)', feats)\n",
        "            if match:\n",
        "                gender = match.group(1)\n",
        "            words.append(word)\n",
        "            word_features.append({'pos': pos, 'gender': gender})\n"
      ],
      "metadata": {
        "id": "zxrmeVqcz5xH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Прибираємо дублікати"
      ],
      "metadata": {
        "id": "H7u9fM9F0L9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set()\n",
        "unique_data = []\n",
        "for word, feat in zip(words, word_features):\n",
        "    if word not in unique_words and len(word) > 2:\n",
        "        unique_words.add(word)\n",
        "        unique_data.append((word, feat))\n",
        "\n",
        "words = [wd[0] for wd in unique_data]\n",
        "word_features = [wd[1] for wd in unique_data]\n"
      ],
      "metadata": {
        "id": "TeHVRPnP0TuJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Відображення символів"
      ],
      "metadata": {
        "id": "de9kQGzV0Vvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "chars.extend(['<S>', '<E>', '<UNK>'])\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "cXQta49Z0cTk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### теги POS і стать"
      ],
      "metadata": {
        "id": "461oRXhX0hAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = sorted(list(set([feat['pos'] for feat in word_features])))\n",
        "genders = sorted(list(set([feat['gender'] for feat in word_features if feat['gender'] is not None])))"
      ],
      "metadata": {
        "id": "zbvRz0kE0jdM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Створення відображень"
      ],
      "metadata": {
        "id": "yE3j9Kbk0oyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_idx = {pos: idx for idx, pos in enumerate(pos_tags)}\n",
        "gender_to_idx = {gender: idx for idx, gender in enumerate(genders)}\n"
      ],
      "metadata": {
        "id": "8aMeMtKI0pyI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Створення датасету"
      ],
      "metadata": {
        "id": "HcUaTVCK0uei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(words, word_features, block_size):\n",
        "    X_char, X_pos, X_gender, Y = [], [], [], []\n",
        "    for word, feat in zip(words, word_features):\n",
        "        context = [stoi['<S>']] * block_size\n",
        "        pos_idx = pos_to_idx[feat['pos']]\n",
        "        gender_idx = gender_to_idx.get(feat['gender'], -1)\n",
        "        for ch in word + '<E>':\n",
        "            ix = stoi.get(ch, stoi['<UNK>'])\n",
        "            X_char.append(context)\n",
        "            X_pos.append(pos_idx)\n",
        "            X_gender.append(gender_idx)\n",
        "            Y.append(ix)\n",
        "            context = context[1:] + [ix]\n",
        "    X_char = torch.tensor(X_char)\n",
        "    X_pos = torch.tensor(X_pos)\n",
        "    X_gender = torch.tensor(X_gender)\n",
        "    Y = torch.tensor(Y)\n",
        "    return X_char, X_pos, X_gender, Y\n",
        "\n",
        "block_size = 5\n",
        "X_char, X_pos, X_gender, Y = build_dataset(words, word_features, block_size)\n"
      ],
      "metadata": {
        "id": "p0jtZhTq00p0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визначення моделі"
      ],
      "metadata": {
        "id": "RfwxFn2i01Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pos_size, gender_size, feature_dim=32):\n",
        "        super(WordLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_embedding = nn.Embedding(pos_size, feature_dim)\n",
        "        self.gender_embedding = nn.Embedding(gender_size + 1, feature_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + 2 * feature_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x_char, x_pos, x_gender, hidden=None):\n",
        "        embeds = self.embedding(x_char)\n",
        "        pos_embeds = self.pos_embedding(x_pos).unsqueeze(1).repeat(1, x_char.size(1), 1)\n",
        "        gender_embeds = self.gender_embedding(x_gender + 1).unsqueeze(1).repeat(1, x_char.size(1), 1)\n",
        "        lstm_input = torch.cat([embeds, pos_embeds, gender_embeds], dim=2)\n",
        "        out, hidden = self.lstm(lstm_input, hidden)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out, hidden\n",
        "\n",
        "embedding_dim = 50\n",
        "hidden_dim = 128\n",
        "feature_dim = 32\n",
        "pos_size = len(pos_tags)\n",
        "gender_size = len(genders)\n",
        "model = WordLSTM(vocab_size, embedding_dim, hidden_dim, pos_size, gender_size, feature_dim)\n"
      ],
      "metadata": {
        "id": "KQerd-AW06uI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тренуємо модель"
      ],
      "metadata": {
        "id": "nLwzQ1L61B-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    permutation = torch.randperm(X_char.size()[0])\n",
        "\n",
        "    for i in range(0, X_char.size()[0], batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x_char = X_char[indices]\n",
        "        batch_x_pos = X_pos[indices]\n",
        "        batch_x_gender = X_gender[indices]\n",
        "        batch_y = Y[indices]\n",
        "\n",
        "        model.zero_grad()\n",
        "        output, _ = model(batch_x_char, batch_x_pos, batch_x_gender)\n",
        "        loss = loss_function(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * batch_x_char.size(0)\n",
        "\n",
        "    average_loss = epoch_loss / len(X_char)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbsNukqs0_9y",
        "outputId": "8d777979-1ece-4386-f138-5d54d3248144"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 1.8155\n",
            "Epoch 2/20, Loss: 1.6117\n",
            "Epoch 3/20, Loss: 1.5398\n",
            "Epoch 4/20, Loss: 1.4895\n",
            "Epoch 5/20, Loss: 1.4507\n",
            "Epoch 6/20, Loss: 1.4179\n",
            "Epoch 7/20, Loss: 1.3908\n",
            "Epoch 8/20, Loss: 1.3665\n",
            "Epoch 9/20, Loss: 1.3462\n",
            "Epoch 10/20, Loss: 1.3280\n",
            "Epoch 11/20, Loss: 1.3115\n",
            "Epoch 12/20, Loss: 1.2966\n",
            "Epoch 13/20, Loss: 1.2823\n",
            "Epoch 14/20, Loss: 1.2702\n",
            "Epoch 15/20, Loss: 1.2580\n",
            "Epoch 16/20, Loss: 1.2479\n",
            "Epoch 17/20, Loss: 1.2381\n",
            "Epoch 18/20, Loss: 1.2296\n",
            "Epoch 19/20, Loss: 1.2206\n",
            "Epoch 20/20, Loss: 1.2125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Утворення слів за допомогою фільтрів"
      ],
      "metadata": {
        "id": "qgreh68B1Mhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_word(model, stoi, itos, block_size, pos_filter=None, gender_filter=None, max_length=12):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        context = torch.tensor([[stoi['<S>']] * block_size])\n",
        "        word = ''\n",
        "        hidden = None\n",
        "\n",
        "        if pos_filter is not None and pos_filter in pos_to_idx:\n",
        "            pos_idx = torch.tensor([pos_to_idx[pos_filter]])\n",
        "        else:\n",
        "            pos_idx = torch.tensor([np.random.choice(len(pos_tags))])\n",
        "        if gender_filter is not None and gender_filter in gender_to_idx:\n",
        "            gender_idx = torch.tensor([gender_to_idx[gender_filter]])\n",
        "        else:\n",
        "            gender_idx = torch.tensor([np.random.choice(len(genders)) - 1])\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output, hidden = model(context, pos_idx, gender_idx)\n",
        "            prob = torch.softmax(output, dim=1)\n",
        "            char_ind = torch.multinomial(prob, num_samples=1).item()\n",
        "            char = itos[char_ind]\n",
        "            if char == '<E>':\n",
        "                break\n",
        "            word += char\n",
        "            context = torch.cat([context[:, 1:], torch.tensor([[char_ind]])], dim=1)\n",
        "        return word\n"
      ],
      "metadata": {
        "id": "4qRqKgkY1NZb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8FEOtiiRr0f",
        "outputId": "727f0908-df29-447b-e04f-0c93ce1d566b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available POS tags: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']\n",
            "Available genders: ['Fem', 'Masc', 'Neut']\n",
            "Generated feminine noun: філкувами<UNK><UNK><UNK>\n",
            "Generated feminine noun: загреснях<UNK><UNK><UNK>\n",
            "Generated feminine noun: молина<UNK><UNK><UNK><UNK><UNK><UNK>\n",
            "Generated feminine noun: мати<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>\n",
            "Generated feminine noun: співпрексуті\n",
            "Generated verb: записаєш<UNK><UNK><UNK><UNK>\n",
            "Generated verb: зоблюкувати<UNK>\n",
            "Generated verb: моржлала<UNK><UNK><UNK><UNK>\n",
            "Generated verb: підобрали<UNK><UNK><UNK>\n",
            "Generated verb: поїждять<UNK><UNK><UNK><UNK>\n"
          ]
        }
      ],
      "source": [
        "print(\"Available POS tags:\", pos_tags)\n",
        "print(\"Available genders:\", genders)\n",
        "\n",
        "#  feminine nouns\n",
        "for _ in range(5):\n",
        "    word = generate_word(model, stoi, itos, block_size, pos_filter='NOUN', gender_filter='Fem')\n",
        "    print(f\"Generated feminine noun: {word}\")\n",
        "\n",
        "#  verbs\n",
        "for _ in range(5):\n",
        "    word = generate_word(model, stoi, itos, block_size, pos_filter='VERB')\n",
        "    print(f\"Generated verb: {word}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}